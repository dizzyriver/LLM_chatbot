{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfa7d0-a088-4ac5-8c02-1ddf7fd3a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "import json\n",
    "import yaml\n",
    "import hashlib\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_student_answers(student_id):\n",
    "    \"\"\"\n",
    "    Reads topics from txt files and adds to a dataframe. Each topic can be in a separate file\n",
    "    \"\"\"\n",
    "    exam = []\n",
    "    #path where we store the exam topic txt files\n",
    "    exam_answers_path = os.getenv(\"EXAM_ANSWERS\")\n",
    "\n",
    "    #read in the exam topic files and return as a pandas DataFrame\n",
    "    student_answers = pd.read_csv(os.path.join(exam_answers_path,student_id,\"student_answers.csv\"))\n",
    "    return student_answers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ae0f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classroom_report(student_ids):\n",
    "    \n",
    "    classroom_data = []\n",
    "\n",
    "    exam_answers_path = os.getenv(\"EXAM_ANSWERS\")\n",
    "    for student_id in os.listdir(exam_answers_path):\n",
    "        try:\n",
    "            student_answers = pd.read_csv(os.path.join(exam_answers_path,student_id,\"student_answers_scored.csv\"))\n",
    "            \n",
    "            with open(os.path.join(exam_answers_path,student_id,\"config.yaml\"), 'r') as file:\n",
    "                config = yaml.safe_load(file)\n",
    "            config[\"mean_score\"] = student_answers['Rating'].mean()\n",
    "            config[\"median_score\"] = student_answers['Rating'].median()\n",
    "            config[\"student_id\"] = student_id\n",
    "            classroom_data.append(config)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    classroom_data = pd.DataFrame(classroom_data)\n",
    "    \n",
    "    #if \"classroom_data.csv\" in os.listdir(exam_answers_path):\n",
    "        #existing_classroom_data = pd.read_csv(os.path.join(exam_answers_path,\"classroom_data.csv\"))\n",
    "        #classroom_data = pd.concat([classroom_data, existing_classroom_data])\n",
    "\n",
    "    classroom_data = classroom_data.sort_values(by=\"mean_score\",ascending=False)\n",
    "    classroom_data.to_csv(os.path.join(exam_answers_path,\"classroom_data.csv\"),index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6ba468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ac7fd72d0e90f4f7569b8eda89e0421c\n",
      "f9e00b77f118b041da89e803091cce78\n",
      "46c996fe3d9c85c8f719d000bdee455d\n",
      "2ed9ed20bdf66c2f5e14ca590608d17f\n",
      "e6d1c57ce083e1bca7d96b508b36c677\n",
      "13cc4000c382b5668120e67969b4d378\n",
      "25a973408e531d90b48c8621a6184aea\n",
      "fa6888b1b4b750fb3da91a98d1692199\n",
      "7f87ce89256e2222c5d26691ddec4848\n",
      "8604d1b7291b4c12abf27d2082513251\n",
      "a792a4a08103bc2e509300f2a3149069\n",
      "22fee230421fb54af61f3eb4eb6feeef\n",
      "dc0d047d53f69887389775a88b81f84f\n",
      "93a7dd191c53ba3166f328418f806ed5\n",
      "6ee4dbd9441adb27e878e366deba2073\n",
      "8becbd312e5d194b4a1c223b86168bb1\n",
      "29d56042cfc1bd6008d88a03fc89e8ab\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "601b9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_ids_for_scoring():\n",
    "    \"\"\"Look at the existing classroom_data and only select new student_ids \n",
    "    that have not already been scored\"\"\"\n",
    "    exam_answers_path = os.getenv(\"EXAM_ANSWERS\")\n",
    "    classroom_data = pd.read_csv(os.path.join(exam_answers_path,\"classroom_data.csv\"))\n",
    "    scored_students = list(classroom_data[\"student_id\"])\n",
    "    student_ids  = os.listdir(exam_answers_path)\n",
    "    new_students = [student_id for student_id in  student_ids if student_id not in scored_students and len(student_id) == 32]\n",
    "    return new_students\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "791f41c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac7fd72d0e90f4f7569b8eda89e0421c',\n",
       " '2ed9ed20bdf66c2f5e14ca590608d17f',\n",
       " 'e6d1c57ce083e1bca7d96b508b36c677',\n",
       " 'fa6888b1b4b750fb3da91a98d1692199',\n",
       " '8604d1b7291b4c12abf27d2082513251',\n",
       " 'a792a4a08103bc2e509300f2a3149069',\n",
       " '93a7dd191c53ba3166f328418f806ed5',\n",
       " '8becbd312e5d194b4a1c223b86168bb1']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_student_ids_for_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3655f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_answer_to_long(student_answers, num_questions):\n",
    "    \n",
    "    long_student_answers = pd.DataFrame()\n",
    "\n",
    "    for i in range(1, num_questions + 1):\n",
    "        temp_df = student_answers[[f'Question {i}', f'Student Answer {i}', f'Teacher Answer {i}', 'topic','topic_hash']].copy()\n",
    "        temp_df.columns = ['Question', 'Student Answer', 'Teacher Answer', 'topic', 'topic_hash']\n",
    "        long_student_answers = pd.concat([long_student_answers, temp_df], ignore_index=True)\n",
    "    \n",
    "    return long_student_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_card(exam_scores,student_id):\n",
    "    exam_scores['Rating'] = exam_scores['Rating'].apply(int)\n",
    "    print(f\"\"\"mean score {exam_scores['Rating'].mean()}, median score {exam_scores['Rating'].median()}\"\"\")\n",
    "    path = os.path.join(os.getenv(\"EXAM_ANSWERS\"),student_id,\"student_answers_scored.csv\")\n",
    "    exam_scores.to_csv(path,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2acea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_exam(domain, exam_answers, prompt_template_fname, llm):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a set a topic, a set of questions and answers by a student and teacher we score\n",
    "    how well the students answer follows the teacher answer.\n",
    "    \"\"\"    \n",
    "    response_schemas = []\n",
    "    rating_schema =  ResponseSchema(name=f\"\"\"Rating\"\"\",\n",
    "                                          description=f\"\"\"Rating for the answer\"\"\"\n",
    "                                         )\n",
    "    response_schemas.append(rating_schema)\n",
    "    \n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    prompt_path = os.path.join(os.getenv(\"PROMPTS\"),prompt_template_fname)\n",
    "    with open(prompt_path,\"r\") as file:\n",
    "        template_string = file.read()\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in tqdm(exam_answers.iterrows()):\n",
    "        \n",
    "        message = prompt_template.format_messages(\n",
    "            context=row[\"topic\"],\n",
    "            domain=domain,\n",
    "            question=row[f\"Question\"],\n",
    "            model_answer=row[\"Teacher Answer\"],\n",
    "            student_answer=row[\"Student Answer\"],\n",
    "            format_instructions=format_instructions\n",
    "            )\n",
    "\n",
    "        response = llm(message)\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        output_dict[\"Question\"] = row[\"Question\"]\n",
    "        output_dict[\"Teacher Answer\"] = row[\"Teacher Answer\"]\n",
    "        output_dict[\"Student Answer\"] = row[\"Student Answer\"]\n",
    "        results.append(output_dict)\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140188fd",
   "metadata": {},
   "source": [
    "## Score exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26c74de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring student ac7fd72d0e90f4f7569b8eda89e0421c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:33,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 8.285714285714286, median score 9.0\n",
      "scoring student 2ed9ed20bdf66c2f5e14ca590608d17f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:25,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 8.357142857142858, median score 9.0\n",
      "scoring student e6d1c57ce083e1bca7d96b508b36c677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:26,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 8.446428571428571, median score 9.0\n",
      "scoring student fa6888b1b4b750fb3da91a98d1692199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:29,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 8.357142857142858, median score 9.0\n",
      "scoring student 8604d1b7291b4c12abf27d2082513251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:29,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 7.0, median score 8.0\n",
      "scoring student a792a4a08103bc2e509300f2a3149069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:28,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 8.285714285714286, median score 9.0\n",
      "scoring student 93a7dd191c53ba3166f328418f806ed5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:28,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 8.464285714285714, median score 9.0\n",
      "scoring student 8becbd312e5d194b4a1c223b86168bb1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [01:36,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 6.946428571428571, median score 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#model = \"gpt-3.5-turbo\"\n",
    "model = \"gpt-4-turbo-preview\"\n",
    "\n",
    "#student_ids = [\"2ed9ed20bdf66c2f5e14ca590608d17f\",\"fa6888b1b4b750fb3da91a98d1692199\"]\n",
    "student_ids = get_student_ids_for_scoring()\n",
    "\n",
    "domain = \"HR and workforce transformation\"\n",
    "num_questions = 4\n",
    "prompt_template_fname = \"teacher_score_exam_prompt.txt\"\n",
    "llm = ChatOpenAI(temperature=0.0, model=model)\n",
    "\n",
    "for student_id in student_ids:\n",
    "    print(f\"\"\"scoring student {student_id}\"\"\")\n",
    "    student_answers = load_student_answers(student_id)\n",
    "    student_answers = student_answer_to_long(student_answers, num_questions)\n",
    "    exam_scores = score_exam(domain, student_answers, prompt_template_fname, llm)\n",
    "    report_card(exam_scores,student_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec1afa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_answers_path = os.getenv(\"EXAM_ANSWERS\")\n",
    "student_ids  = os.listdir(exam_answers_path)\n",
    "student_ids = [student_id for student_id in  student_ids if len(student_id) == 32]\n",
    "classroom_data = classroom_report(student_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79d4c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9fa0686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac7fd72d0e90f4f7569b8eda89e0421c',\n",
       " 'f9e00b77f118b041da89e803091cce78',\n",
       " '46c996fe3d9c85c8f719d000bdee455d',\n",
       " '2ed9ed20bdf66c2f5e14ca590608d17f',\n",
       " 'e6d1c57ce083e1bca7d96b508b36c677',\n",
       " '13cc4000c382b5668120e67969b4d378',\n",
       " '25a973408e531d90b48c8621a6184aea',\n",
       " 'fa6888b1b4b750fb3da91a98d1692199',\n",
       " '7f87ce89256e2222c5d26691ddec4848',\n",
       " '8604d1b7291b4c12abf27d2082513251',\n",
       " 'a792a4a08103bc2e509300f2a3149069',\n",
       " '22fee230421fb54af61f3eb4eb6feeef',\n",
       " 'dc0d047d53f69887389775a88b81f84f',\n",
       " '93a7dd191c53ba3166f328418f806ed5',\n",
       " '6ee4dbd9441adb27e878e366deba2073',\n",
       " '8becbd312e5d194b4a1c223b86168bb1',\n",
       " '29d56042cfc1bd6008d88a03fc89e8ab']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_answers_path = os.getenv(\"EXAM_ANSWERS\")\n",
    "student_ids  = os.listdir(exam_answers_path)\n",
    "student_ids = [student_id for student_id in  student_ids if len(student_id) == 32]\n",
    "classroom_data = classroom_report(student_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be22923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
