{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d40bf-9c45-4dd8-a4f8-f0f5335c205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c1c2c-edce-4611-b400-a24ab86be7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exam(domain, exam_topics, num_questions, prompt_template_fname, llm):\n",
    "\n",
    "    “”\"\n",
    "    Given a topic in a domain generate num_questions question,answer pairs\n",
    "    about the topic.\n",
    "    “”\"\n",
    "\n",
    "    response_schemas = []\n",
    "    for n in range(1,num_questions+1):\n",
    "        question_schema =  ResponseSchema(name=f\"\"\"Question {n}\"\"\",\n",
    "                                          description=f\"\"\"Question number {n} of the exam\"\"\"\n",
    "                                         )\n",
    "        response_schemas.append(question_schema)\n",
    "        answer_schema =  ResponseSchema(name=f\"\"\"Teacher Answer {n}\"\"\",\n",
    "                                          description=f\"\"\"Answer number {n} of the exam\"\"\"\n",
    "                                         )\n",
    "        response_schemas.append(answer_schema)\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "    prompt_path = os.path.join(os.getenv(\"PROMPTS\"),prompt_template_fname)\n",
    "    with open(prompt_path,\"r\") as file:\n",
    "        template_string = file.read()\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "    for idx, row in tqdm(exam_topics.iterrows()):\n",
    "\n",
    "        message = prompt_template.format_messages(\n",
    "                    topic=row[\"exam_topic\"],\n",
    "                    domain=domain,\n",
    "                    num_questions=num_questions,\n",
    "                    format_instructions=format_instructions)\n",
    "\n",
    "        response = llm(message)\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        output_dict[\"topic_hash\"] = hashlib.md5(row[\"exam_topic\"].encode()).hexdigest()\n",
    "        output_dict[\"topic\"]=row[\"exam_topic\"]\n",
    "\n",
    "\n",
    "        path = os.path.join(os.getenv(\"EXAM_TOPICS\"),f\"\"\"topic_{idx+1}_exam_qa.json\"\"\")\n",
    "        with open(path, \"w\") as file:\n",
    "            json.dump(output_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30202644-ee9a-422e-ae44-501a60499cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exam_topics():\n",
    "    \"\"\"\n",
    "    Reads topics from txt files and adds to a dataframe. Each topic can be in a separate file\n",
    "    \"\"\"\n",
    "    exam_topics = []\n",
    "    #path where we store the exam topic txt files\n",
    "    exam_topics_path = os.getenv(\"EXAM_TOPICS\")\n",
    "\n",
    "    #read in the exam topic files and return as a pandas DataFrame\n",
    "    for file in list(filter(lambda f: f.endswith(\".txt\"),os.listdir(exam_topics_path))):\n",
    "        with open(os.path.join(exam_topics_path,file),'r') as file:\n",
    "            exam_topics.append(file.read())\n",
    "    exam_topics = pd.DataFrame(exam_topics)\n",
    "    exam_topics.columns = [\"exam_topic\"]\n",
    "    return exam_topics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e32a71-c22e-494f-ba02-538b8d25f81b",
   "metadata": {},
   "source": [
    "## Generate exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806c089-9721-4e7c-afc6-c64470ce1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"gpt-3.5-turbo\"\n",
    "model = \"gpt-4-turbo-preview\"\n",
    "exam_topics = get_exam_topics()\n",
    "domain = \"HR and workforce transformation\"\n",
    "num_questions = 4\n",
    "prompt_template_fname = \"teacher_generate_exam_prompt.txt\"\n",
    "llm = ChatOpenAI(temperature=0.0, model=model)\n",
    "\n",
    "generate_exam(domain, exam_topics, num_questions, prompt_template_fname, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a27abe-d479-45bf-822c-0c935cb029cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
